{
    "generate_samples": false,
    "torch_compile": true,
    "torch_compile_mode": "default",
    "hf_load_weights": false,
    "hf_path": "meta-llama/Llama-3.1-8B",
    "attn_type": "sdpa",
    "is_headless": true,
    "model_cls": "LlamaForCausalLM",
    "vocab_size": 128256,
    "max_position_embeddings": 16384
}