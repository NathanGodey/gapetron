{
    "generate_samples": false,
    "torch_compile": true,
    "torch_compile_mode": "default",
    "hf_load_weights": false,
    "hf_path": "nthngdy/olmo24b-random",
    "attn_type": "flash_attention_3",
    "is_headless": false,
    "model_cls": "Olmo2ForCausalLM",
    "vocab_size": 128256,
    "max_position_embeddings": 16384
}