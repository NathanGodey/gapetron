{
    "generate_samples": false,
    "torch_compile": true,
    "torch_compile_mode": "default",
    "hf_load_weights": false,
    "hf_path": "meta-llama/Llama-3.2-1B",
    "hf_overwrite": {
        "rope_scaling": null,
        "tie_word_embeddings": false
    },
    "attn_type": "sdpa",
    "is_headless": false,
    "model_cls": "LlamaForCausalLM",
    "vocab_size": 128256,
    "max_position_embeddings": 16384
}